
































# importing libraries
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

sns.set(style='whitegrid')


#loading the dataset
df = pd.read_csv('netflix.csv')
df.head()





df.shape





df.describe()





df.info()








df.isna().sum()











# convert data type (form object to datetime64)
df['date_added'] = pd.to_datetime(df['date_added'].astype(str).str.strip(), format="%B %d, %Y", errors='coerce')


df.info()





#checking the entries with null dates
df[df.date_added.isnull()]


most_recent_date=df['date_added'].max() # find the most recent entry in the `date_added` column
print(f'Most recent release date: {most_recent_date}')

na_values = {
    'rating': 'Unknown',
    'cast': 'Unknown',
    'country': 'Unknown',
    'director': 'Unknown',
    'date_added': most_recent_date
}
df.fillna(na_values, inplace=True)


# checking an imputed entry
df[df['show_id'] == 's5138']





df.isna().sum()














df.type.value_counts() #check the actual counts


# now plot the data in a countplot
sns.countplot(x = 'type', data=df)
plt.title('Count vs Type of Show')








print(f'There are {len(df["country"].value_counts())} unique countries')
print(df['country'].value_counts().head(10))





#plot the countplot
sns.countplot(y = 'country', order = df['country'].value_counts().index[0:10], data=df)

sns.countplot(
    y = 'country',
    hue = 'country',  
    order = df['country'].value_counts().index[0:10],
    data = df,
)

plt.title('Top 10 Countries on Netflix')








# Create dfferent copies od dataset filtering out according to its type
movie_countries = df[df['type'] == 'Movie']
show_countries = df[df['type'] == 'TV Show']


# Plot the data

# first the movie countries
plt.figure(figsize=(12, 6))
sns.countplot(
    y = 'country',
    hue = 'country',
    order = df['country'].value_counts().index[0:10],
    data = movie_countries,
)
plt.title('Top 10 Countries producing Movies on Netflix')


# and the shows
plt.figure(figsize=(12, 6))
sns.countplot(
    y = 'country',
    hue = 'country',
    order = df['country'].value_counts().index[0:10],
    data = show_countries,
)
plt.title('Top 10 Countries producing TV Show on Netflix')








df.rating.value_counts() #lets check the count of all ratings


#plot the data
plt.figure(figsize=(12, 6))
sns.countplot(
    y = 'rating',
    hue = 'rating',
    order = movie_countries['rating'].value_counts().index[0:10],
    data = movie_countries,
)
plt.title('Top 10 Movie ratings on Netflix')


#plot the data
plt.figure(figsize=(12, 6))
sns.countplot(
    y = 'rating',
    hue = 'rating',
    order = show_countries['rating'].value_counts().index[0:10],
    data = show_countries,
)
plt.title('Top 10 Show ratings on Netflix')










df.release_year.value_counts()[:20] # checking the top 20 release years


# plot the data

## The whole count
plt.figure(figsize=(12, 6))
sns.countplot(
    x = 'release_year',
    hue = 'release_year',
    order = df['release_year'].value_counts().index[0:20],
    data = df,
)
plt.title('Top 20 release year(s) on Netflix')


## Counts divided as per movies and shows
plt.figure(figsize=(12, 6))
sns.countplot(
    x = 'release_year',
    hue = 'release_year',
    order = movie_countries['release_year'].value_counts().index[0:20],
    data = movie_countries,
)
plt.title('Top 20 Movie release year(s) on Netflix')


plt.figure(figsize=(12, 6))
sns.countplot(
    x = 'release_year',
    hue = 'release_year',
    order = show_countries['release_year'].value_counts().index[0:20],
    data = show_countries,
)
plt.title('Top 20 TV Show release year(s) on Netflix')









plt.figure(figsize=(12, 8))
sns.countplot(
    y = 'listed_in',
    hue = 'listed_in',
    order = df['listed_in'].value_counts().index[0:20],
    data = df,
)
plt.title('Top 20 Genres on Netflix')


plt.figure(figsize=(12, 8))
sns.countplot(
    y = 'listed_in',
    hue = 'listed_in',
    order = movie_countries['listed_in'].value_counts().index[0:20],
    data = movie_countries,
)
plt.title('Top 20 Movie Genres on Netflix')


plt.figure(figsize=(12, 8))
sns.countplot(
    y = 'listed_in',
    hue = 'listed_in',
    order = show_countries['listed_in'].value_counts().index[0:20],
    data = show_countries,
)
plt.title('Top 20 Show Genres on Netflix')








# Step 1: Clean data (Remove "Unknown" actors and genres)
df_valid = df[(df['cast'] != 'Unknown') & (df['listed_in'] != 'Unknown')].copy()

# Step 2: Explode the columns
df_valid['cast'] = df_valid['cast'].str.split(', ')
df_valid['listed_in'] = df_valid['listed_in'].str.split(', ')
df_exploded = df_valid.explode('cast').explode('listed_in')

# Step 3: Count top 20 actors
top_9_actors = df_exploded['cast'].value_counts().head(9).index.tolist()

# Step 4: Create a pivot table (actor Ã— genre)
pivot = df_exploded[df_exploded['cast'].isin(top_9_actors)] \
    .groupby(['cast', 'listed_in']) \
    .size() \
    .unstack(fill_value=0)

# Normalize to binary (presence)
pivot = (pivot > 0).astype(int)

# Step 1: Count genres
genre_counts = df_exploded['listed_in'].value_counts()
genre_counts = genre_counts.sort_values(ascending=False)  # .head(20)

labels = genre_counts.index.tolist()
values = genre_counts.values.tolist()

# Step 2: Calculate angles
angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()

# Step 3: Close the radar chart loop
values += values[:1]
angles += angles[:1]
labels += labels[:1]  # optional for labeling the loop, else omit

# Step 4: Plot radar chart
fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={'polar': True})
ax.set_theta_offset(np.pi / 2)
ax.set_theta_direction(-1)

ax.plot(angles, values, linewidth=2)
ax.fill(angles, values, alpha=0.25)

ax.set_xticks(angles[:-1])  # exclude the duplicate angle
ax.set_xticklabels(labels[:-1], fontsize=9)

ax.set_title("Genre Distribution on Netflix", size=14, pad=20)
ax.set_yticklabels([])

plt.tight_layout()
plt.show()





# Radar Chart Function
def plot_radar(actor, data, ax):
    labels = list(data.columns)
    values = data.loc[actor].values.tolist()

    # Close the radar loop
    values += values[:1]           # Add the first value at the end
    labels += labels[:1]           # Also repeat the first label
    angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()
    
    ax.set_theta_offset(np.pi / 2)  # Rotate the plot for better alignment
    ax.set_theta_direction(-1)      # Set the direction of the plot
    
    ax.plot(angles, values, linewidth=2)
    ax.fill(angles, values, alpha=0.25)
    ax.set_title(actor, size=10, pad=20)
    ax.set_xticks(angles)
    ax.set_xticklabels(labels, fontsize=9, ha='center')
    ax.set_yticklabels([])

# Plot radar charts for each top actor in a 3x3 grid layout
fig, axs = plt.subplots(3, 3, figsize=(30, 30), subplot_kw={'polar': True})

# Flatten the axs array to iterate through easily
axs = axs.flatten()

# Plot each radar chart
for i, actor in enumerate(top_9_actors):
    plot_radar(actor, pivot, axs[i])

# Adjust the layout
plt.tight_layout()
plt.show()


# Clean data (Remove "Unknown" actors and genres)
df_valid = df[(df['cast'] != 'Unknown') & (df['listed_in'] != 'Unknown')].copy()

# Step 2: Explode the columns
df_valid['cast'] = df_valid['cast'].str.split(', ')
df_valid['listed_in'] = df_valid['listed_in'].str.split(', ')
df_exploded = df_valid.explode('cast').explode('listed_in')

# Parse and add duration in minutes
def parse_duration(x):
    if pd.isna(x):
        return None
    if 'min' in x:
        return int(x.replace(' min', ''))
    elif 'Season' in x:
        return int(x.split(' ')[0]) * 12 * 30  # Approx. 1 season = 12ep, 30 mins each
    return None

df_exploded['duration_min'] = df_exploded['duration'].apply(parse_duration)

# Get top 9 actors
top_9_actors = df_exploded['cast'].value_counts().head(9).index.tolist()

# Step 5: Create pivot table (actor x genre with sum of durations)
pivot = df_exploded[df_exploded['cast'].isin(top_9_actors)] \
    .groupby(['cast', 'listed_in'])['duration_min'] \
    .sum() \
    .unstack(fill_value=0)

# Radar Chart Function
def plot_radar(actor, data, ax):
    labels = list(data.columns)
    values = data.loc[actor].values.tolist()

    # Normalize to a max of 100 for better comparison (optional)
    max_val = max(values) if max(values) != 0 else 1
    values = [(v / max_val) * 100 for v in values]

    # Close the radar loop
    values += values[:1]
    labels += labels[:1]
    angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()
    
    ax.set_theta_offset(np.pi / 2)
    ax.set_theta_direction(-1)
    
    ax.plot(angles, values, linewidth=2)
    ax.fill(angles, values, alpha=0.25)
    ax.set_title(actor, size=12, pad=20)
    ax.set_xticks(angles)
    ax.set_xticklabels(labels, fontsize=9)
    ax.set_yticklabels([])

# Plot radar charts in 3x3 layout
fig, axs = plt.subplots(3, 3, figsize=(30, 30), subplot_kw={'polar': True})
axs = axs.flatten()

for i, actor in enumerate(top_9_actors):
    plot_radar(actor, pivot, axs[i])

plt.tight_layout()
plt.show()








# Filter out unknowns
df_valid = df[(df['listed_in'] != 'Unknown') & (df['release_year'].notna())].copy()

# Explode the genres
df_valid['listed_in'] = df_valid['listed_in'].str.split(', ')
df_exploded = df_valid.explode('listed_in')

# Group by genre and year
genre_year_counts = df_exploded.groupby(['release_year', 'listed_in']).size().reset_index(name='count')

# Pivot the data to get genres as columns
genre_trend = genre_year_counts.pivot(index='release_year', columns='listed_in', values='count').fillna(0)

# Only keep top N genres by total count
top_genres = df_exploded['listed_in'].value_counts().head(10).index
genre_trend = genre_trend[top_genres]

# Plot
plt.figure(figsize=(14, 8))
for genre in genre_trend.columns:
    plt.plot(genre_trend.index, genre_trend[genre], label=genre)

plt.title("Genre Popularity Over Time")
plt.xlabel("Release Year")
plt.ylabel("Number of Titles")
plt.legend(loc='upper left', bbox_to_anchor=(1, 1))
plt.grid(True)
plt.tight_layout()
plt.show()





# 1. Type (Movie = 1, TV Show = 0)
df['is_movie'] = df['type'].apply(lambda x: 1 if x == 'Movie' else 0)

# 2. Extract year and month from date_added
df['year_added'] = df['date_added'].dt.year
df['month_added'] = df['date_added'].dt.month

# 3. Convert duration into numerical value
def parse_duration(x):
    if pd.isna(x):
        return None
    if 'min' in x:
        return int(x.replace(' min', ''))
    elif 'Season' in x:
        return int(x.split(' ')[0]) * 12 * 30  # Approx. 1 season = 12ep, 30 mins each
    elif 'Unknown' in x:
        return None
    return None

df['duration_num'] = df['duration'].apply(parse_duration)

# 4. Map rating to approximate audience age
rating_map = {
    'G': 0, 'TV-G': 0,
    'PG': 10, 'TV-PG': 10,
    'PG-13': 13, 'TV-14': 14,
    'R': 17, 'TV-MA': 18,
    'NC-17': 18,
}
df['rating_num'] = df['rating'].map(rating_map)

# 5. Keep only numeric columns
correlation_df = df[['is_movie', 'release_year', 'year_added', 'month_added', 'duration_num', 'rating_num']]

# Drop rows with missing values
correlation_df = correlation_df.dropna()

# 6. Plot the heatmap
plt.figure(figsize=(10, 7))
sns.heatmap(correlation_df.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()








# Create a 2x2 canvas
fig, axs = plt.subplots(2, 2, figsize=(18, 10))
axs = axs.flatten()

# 1. duration_num vs rating_num
sns.scatterplot(data=correlation_df, x='rating_num', y='duration_num', ax=axs[0])
axs[0].set_title('Duration vs Rating Age')

# 2. release_year vs duration_num
sns.scatterplot(data=correlation_df, x='release_year', y='duration_num', ax=axs[1])
axs[1].set_title('Duration vs Release Year')

# 3. year_added vs release_year
sns.scatterplot(data=correlation_df, x='release_year', y='year_added', ax=axs[2])
axs[2].set_title('Year Added vs Release Year')

# 4. month_added vs is_movie
sns.countplot(data=correlation_df, x='month_added', hue='is_movie', ax=axs[3])
axs[3].set_title('Month Added vs Type')
axs[3].legend(title='Type', labels=['TV Show', 'Movie'])

plt.tight_layout()
plt.suptitle('Key Netflix Data Insights', fontsize=16, y=1.03)
plt.show()





from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score

df['rating_num'] = df['rating_num'].fillna(df['rating_num'].median())
features = df[['duration_num', 'rating_num', 'release_year']]  # include more if needed
scaled = StandardScaler().fit_transform(features)

kmeans = KMeans(n_clusters=4, random_state=42)
clusters = kmeans.fit_predict(scaled)
df['cluster'] = clusters



from mpl_toolkits.mplot3d import Axes3D
from sklearn.decomposition import PCA

pca_3d = PCA(n_components=3)
reduced_3d = pca_3d.fit_transform(scaled)

fig = plt.figure(figsize=(10, 7))
ax = fig.add_subplot(111, projection='3d')
scatter = ax.scatter(reduced_3d[:, 0], reduced_3d[:, 1], reduced_3d[:, 2],
                     c=clusters, cmap='viridis', s=50, alpha=0.6)
ax.set_title("3D Cluster Visualization (PCA)")
ax.set_xlabel("PCA 1")
ax.set_ylabel("PCA 2")
ax.set_zlabel("PCA 3")
plt.colorbar(scatter)
plt.show()




